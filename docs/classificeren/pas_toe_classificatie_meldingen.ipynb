{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pas classificatie model /algorithme toe op  meldingen\n",
    "\n",
    "Dit classificatie algorithme is een broncode geinspireerd op code van https://gitlab.com/commondatafactory/experiments/signalen-classificatie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = 'model-db-bor-meld.pkl'\n",
    "datafile = 'converted-mor-data-ods.csv'\n",
    "basicresultfile = 'basic-classified-data.csv'\n",
    "extendresultfile = 'extended-classified-data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from nltk.stem.snowball import DutchStemmer\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "# init stemmer\n",
    "stemmer=DutchStemmer(ignore_stopwords=True)\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('dutch'))\n",
    "#print(stop_words)\n",
    "\n",
    "import re\n",
    "re_userid = re.compile(\"^([a-z]+\\\\:)\")\n",
    "def simple_preprocessor(text):\n",
    "    text=text.lower()\n",
    "    # text=re.sub(re_userid,\" \", text) # remove user name id\n",
    "    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "    \n",
    "    # stem words\n",
    "    words=re.split(\"\\\\s+\",text)\n",
    "    stemmed_words=[stemmer.stem(word=word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "model = joblib.load(modelfile) \n",
    "class_labels = model.classes_\n",
    "print('model loaded')\n",
    "#print(len(class_labels))\n",
    "\n",
    "# demodata\n",
    "\n",
    "demo_sentence = ['Ik heb zonnepanelen en zou graag zien dat de gemeente de bomen voor ons huis flink snoeit of weghaalt']\n",
    "demo_texts = [\n",
    "'afval naast container gedumpt',\n",
    "'Koelkast aan de kant van de weg',\n",
    "'Auto met kenteken ZG-378F staat al maanden op een parkeerplaats \\\n",
    "in plaats van naar de Nassualaan te rijden',\n",
    "'Leuk hoor al dat gesnoei maar kan de gemeente dan ook het snoeiafval meenemen\\\n",
    "en dit niet maanden laten liggen op de parkeerplaats',\n",
    "'Mijn buurman heeft illegaal snoeiafval in de bosjes gedumpt samen met een oude fiets',\n",
    "'Mijn buurman heeft illegaal in de bosjes gedumpt  een oude fiets',\n",
    "'Ik heb zonnepanelen en zou graag zien dat de gemeente de bomen voor ons huis flink snoeit of weghaalt',\n",
    "'In de sloot drijft een dode zwaan',\n",
    "    'In de vijver met water cq gracht of sloot drijft een dode zwaan',\n",
    "'Er ligt een dode meeuw op straat' ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "Demonstrate model by showing possible results based on demo inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ik heb zonnepanelen en zou graag zien dat de gemeente de bomen voor ons huis flink snoeit of weghaalt \n",
      "\n",
      "[[67  4 14]]\n",
      "[['Verharding en civiele constructies  - Trillingen en geluid  - Trillingen bij gebruik verharding'\n",
      "  'Afval  - Grofvuil  - Grofvuil niet aangeboden'\n",
      "  'Groen  - Boomoverlast en boomschade  - Boomoverlast (te groot, te veel schaduw)']]\n",
      "[[0.06272713 0.09217629 0.28301133]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "class_labels = model.classes_\n",
    "print(*demo_sentence , \"\\n\")\n",
    "#print(model.predict_log_proba(demo_sentence))\n",
    "\n",
    "y_pred_proba = model.predict_proba(demo_sentence) \n",
    "\n",
    "#dit is het eerste voorspelde item\n",
    "y_pred_proba_item = y_pred_proba[0]\n",
    "\n",
    "#dit zijn de regressie waarden van de  classe van dit item\n",
    "#print (y_pred_proba_item)\n",
    "\n",
    "#maak top n voor elke geclassificeerde item (i=1)\n",
    "n = 3\n",
    "top_n_pred = np.argsort(y_pred_proba, axis=1)[:,-n :]\n",
    "\n",
    "#dit is de hele set met top n's per item i\n",
    "print(top_n_pred)\n",
    "\n",
    "# we printen de labels hulde\n",
    "print(class_labels[top_n_pred])\n",
    "\n",
    "#nu nog de regressie waarde\n",
    "print(y_pred_proba_item[top_n_pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"afval naast container gedumpt\"\n",
      " ----> Afval  - Afvalcontainer  - Vuil naast container \n",
      "\n",
      "\"Koelkast aan de kant van de weg\"\n",
      " ----> Afval  - Grofvuil  - Grofvuil niet aangeboden \n",
      "\n",
      "\"Auto met kenteken ZG-378F staat al maanden op een parkeerplaats in plaats van naar de Nassualaan te rijden\"\n",
      " ----> Parkeren  - Parkeren voertuigen  - Overig foutparkeren \n",
      "\n",
      "\"Leuk hoor al dat gesnoei maar kan de gemeente dan ook het snoeiafval meenemenen dit niet maanden laten liggen op de parkeerplaats\"\n",
      " ----> Groen  - Struiken: snoeien en schade  - Snoeiafval niet verwijderd \n",
      "\n",
      "\"Mijn buurman heeft illegaal snoeiafval in de bosjes gedumpt samen met een oude fiets\"\n",
      " ----> Groen  - Struiken: snoeien en schade  - Snoeiafval niet verwijderd \n",
      "\n",
      "\"Mijn buurman heeft illegaal in de bosjes gedumpt  een oude fiets\"\n",
      " ----> Afval  - Overig afval / lozingen  - Fietswrak \n",
      "\n",
      "\"Ik heb zonnepanelen en zou graag zien dat de gemeente de bomen voor ons huis flink snoeit of weghaalt\"\n",
      " ----> Groen  - Boomoverlast en boomschade  - Boomoverlast (te groot, te veel schaduw) \n",
      "\n",
      "\"In de sloot drijft een dode zwaan\"\n",
      " ----> Riolering en water  - Overlast sloten, vijvers en grachten  - dode dieren (bijv. vis, vogel) \n",
      "\n",
      "\"In de vijver met water cq gracht of sloot drijft een dode zwaan\"\n",
      " ----> Riolering en water  - Overlast sloten, vijvers en grachten  - dode dieren (bijv. vis, vogel) \n",
      "\n",
      "\"Er ligt een dode meeuw op straat\"\n",
      " ----> Overlast personen en dieren  - Overlast dieren of ongedierte  - Dode dieren \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demo_preds = model.predict(demo_texts)\n",
    "tuples = zip(demo_texts, demo_preds)\n",
    "print(*('\\\"{1[0]}\\\"\\n ----> {1[1]} \\n'.format(*k) for k in enumerate(tuples)), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Prediction for inputfiles\n",
    "Drops empty lines which cant be classified are dropped\n",
    "single class no proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77930 rows import as job\n",
      "72899 rows classified exported as result\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(datafile, engine='python')\n",
    "df.head()\n",
    "\n",
    "print(len(df),'rows import as job') \n",
    "df = df.dropna(axis=0, how='any', thresh=None, subset=['omschrijving'], inplace=False)\n",
    "inputs = df[\"omschrijving\"]\n",
    "\n",
    "predicted = model.predict(inputs)\n",
    "df['predicted'] = predicted\n",
    "\n",
    "# save to file\n",
    "print(len(df),'rows classified exported as result') \n",
    "df.to_csv(basicresultfile, index=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended prediction for inputfiles\n",
    "return s \n",
    "p1,p2,p3 with probabilities\n",
    "research into how many p's are required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77930 rows import as job\n",
      " \n",
      "72899 rows extend classified exported as result\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(datafile, engine='python')\n",
    "print(len(df),'rows import as job') \n",
    "df = df.dropna(axis=0, how='any', thresh=None, subset=['omschrijving'], inplace=False)\n",
    "inputs = df[\"omschrijving\"]\n",
    "\n",
    "#change to inputs for production\n",
    "y_pred_proba = model.predict_proba(inputs)\n",
    "\n",
    "#maak top n voor elke geclassificeerde item (i=1)\n",
    "n = 3\n",
    "top_n_pred = np.argsort(y_pred_proba, axis=1)[:,-n :]\n",
    "\n",
    "#dit is de hele set met top n's index voor alle texts\n",
    "#print(top_n_pred)\n",
    "\n",
    "# top_n classes als string voor alle texts\n",
    "top_n_class = class_labels[top_n_pred]\n",
    "#print(top_n_class)\n",
    "\n",
    "#nu nog de regressie waarden van top n voor alle texts\n",
    "top_n_proba = np.sort(y_pred_proba, axis=1)[:,-n :]\n",
    "#print(top_n_proba)\n",
    "\n",
    "#SAVING THE DATA TO DISK\n",
    "#use numpy array to select 1,2,3 th value of n to add to data file\n",
    "print(\" \")\n",
    "for i in range(n): \n",
    "    df[('p_class_' + str(n-i))] = top_n_class[:,i]\n",
    "    df[('p_proba_' + str(n-i))] = top_n_proba[:,i]\n",
    "\n",
    "# save to file\n",
    "print(len(df),'rows extend classified exported as result') \n",
    "df.to_csv(extendresultfile, index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
